{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "import tiktoken\n",
    "#from train_gpt2 import GPT, GPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163840"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16384 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n"
     ]
    }
   ],
   "source": [
    "print(\"First Citizen:\\nBefore we proceed any further, hear me speak.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[2, 3, 34, 4, 5], [1, 2, 3, 4, 5]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches: 10\n",
      "Tokenized data length: 338024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((tensor([[ 5962, 22307,    25,  ...,   760,   327,  1872],\n",
       "          [  385,  1526, 28599,  ...,  1309,   340,   307],\n",
       "          [ 1760,    25,  1497,  ...,   198,  1929,  4316],\n",
       "          ...,\n",
       "          [  262,   198,   805,  ...,   198, 32454,    25],\n",
       "          [  198,  5779,    11,  ...,    25,   788,   760],\n",
       "          [  502,   407,    11,  ...,  3046,   312,  3754]], device='cuda:0'),\n",
       "  tensor([[22307,    25,   198,  ...,   327,  1872,   385],\n",
       "          [ 1526, 28599,   318,  ...,   340,   307,  1760],\n",
       "          [   25,  1497,    11,  ...,  1929,  4316,   462],\n",
       "          ...,\n",
       "          [  198,   805,    11,  ..., 32454,    25,   198],\n",
       "          [ 5779,    11,  1309,  ...,   788,   760,   502],\n",
       "          [  407,    11,   198,  ...,   312,  3754,  7363]], device='cuda:0')),\n",
       " 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, data, B, T, process_rank, num_processes):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        self.process_rank = process_rank\n",
    "        self.num_processes = num_processes\n",
    "        tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "        tokenized_data = tokenizer.encode(data)\n",
    "        self.tok_data = torch.tensor(tokenized_data)\n",
    "        self.starting = self.B * self.T * self.process_rank\n",
    "        self.ending = self.starting + (self.B * self.T)\n",
    "        print(f\"Batches: {len(self.tok_data) // (self.B * self.T)}\")\n",
    "        print(\"Tokenized data length:\", len(self.tok_data))\n",
    "\n",
    "    def next_batch(self):\n",
    "        batch_X = self.tok_data[self.starting:self.ending]\n",
    "        batch_Y = self.tok_data[self.starting + 1: self.ending + 1]\n",
    "        self.starting += self.B * self.T * self.num_processes\n",
    "        self.ending += self.B * self.T * self.num_processes\n",
    "        batch_X = batch_X.view(self.B, self.T).to(\"cuda\")\n",
    "        batch_Y = batch_Y.view(self.B, self.T).to(\"cuda\")\n",
    "        if self.ending >= len(self.tok_data):\n",
    "            self.starting = 0\n",
    "            self.ending = self.B * self.T\n",
    "        return batch_X, batch_Y\n",
    "\n",
    "    def num_of_batches(self):\n",
    "        return len(self.tok_data) // (self.B * self.T)\n",
    "\n",
    "test = DataLoader(text, 500, 64, 0, 0)\n",
    "test.next_batch(), test.num_of_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches: 10\n",
      "Tokenized data length: 338024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5962, 22307,    25,  ...,   760,   327,  1872],\n",
       "         [  385,  1526, 28599,  ...,  1309,   340,   307],\n",
       "         [ 1760,    25,  1497,  ...,   198,  1929,  4316],\n",
       "         ...,\n",
       "         [  262,   198,   805,  ...,   198, 32454,    25],\n",
       "         [  198,  5779,    11,  ...,    25,   788,   760],\n",
       "         [  502,   407,    11,  ...,  3046,   312,  3754]], device='cuda:0'),\n",
       " tensor([[22307,    25,   198,  ...,   327,  1872,   385],\n",
       "         [ 1526, 28599,   318,  ...,   340,   307,  1760],\n",
       "         [   25,  1497,    11,  ...,  1929,  4316,   462],\n",
       "         ...,\n",
       "         [  198,   805,    11,  ..., 32454,    25,   198],\n",
       "         [ 5779,    11,  1309,  ...,   788,   760,   502],\n",
       "         [  407,    11,   198,  ...,   312,  3754,  7363]], device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = DataLoader(text, 500, 64, 0, 1)\n",
    "test.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7363,    25,   318,  ...,   345,    13,   198],\n",
       "         [  198, 44879,    40,  ...,    11,   355,   705],\n",
       "         [ 4246,   567,    11,  ...,    11,   416,   617],\n",
       "         ...,\n",
       "         [   35,    52,  3398,  ...,  4490,   321,    11],\n",
       "         [  345, 13796,   326,  ...,    11,  4167,     0],\n",
       "         [  262,  5822,   288,  ..., 18516,   620,   902]], device='cuda:0'),\n",
       " tensor([[   25,   318,   339,  ...,    13,   198,   198],\n",
       "         [44879,    40,  3535,  ...,   355,   705,  4246],\n",
       "         [  567,    11,   287,  ...,   416,   617,  2863],\n",
       "         ...,\n",
       "         [   52,  3398,  7597,  ...,   321,    11,   345],\n",
       "         [13796,   326,   339,  ...,  4167,     0,   262],\n",
       "         [ 5822,   288,   849,  ...,   620,   902,   284]], device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches: 21126\n",
      "Tokenized data length: 338024\n"
     ]
    }
   ],
   "source": [
    "test2 = DataLoader(text, 1, 16, 0 ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5962, 22307,    25,   198,  8421,   356,  5120,   597,  2252,    11,\n",
       "           3285,   502,  2740,    13,   198,   198]], device='cuda:0'),\n",
       " tensor([[22307,    25,   198,  8421,   356,  5120,   597,  2252,    11,  3285,\n",
       "            502,  2740,    13,   198,   198,  3237]], device='cuda:0'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T = 16, 1024\n",
    "total_batch_size = 524288\n",
    "grad_accum_steps = total_batch_size // (B * T)\n",
    "grad_accum_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 // (320031//16384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26214400"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*50 * (1024 * 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55769"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(int)(len(text) * 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = text[:(int)(len(text) * 0.95)]\n",
    "val = text[(int)(len(text) * 0.95):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1059623, 55770)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.46207300924428"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 - 600000 / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 * 256 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435.703125"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55770 / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9499996862092553, 0.050000313790744606)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)/len(text), len(val)/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1,2,3,4,5])\n",
    "t[3].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches: 10563\n"
     ]
    }
   ],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, data, B, T):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "        tokenized_data = tokenizer.encode(data)\n",
    "        self.tok_data = torch.tensor(tokenized_data)\n",
    "        self.starting = 0\n",
    "        self.ending = self.B * self.T\n",
    "        print(f\"Batches: {len(self.tok_data) // (self.B * self.T)}\")\n",
    "    def next_batch(self):\n",
    "        batch_X = self.tok_data[self.starting:self.ending]\n",
    "        batch_Y = self.tok_data[self.starting + 1: self.ending + 1]\n",
    "        self.starting += self.B * self.T\n",
    "        self.ending += self.B * self.T\n",
    "        batch_X = batch_X.view(self.B, self.T).to(\"cuda\")\n",
    "        batch_Y = batch_Y.view(self.B, self.T).to(\"cuda\")\n",
    "        if self.ending >= len(self.tok_data):\n",
    "            self.starting = 0\n",
    "            self.ending = self.B * self.T\n",
    "        return batch_X, batch_Y\n",
    "\n",
    "trainloader = DataLoader(text, 1, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5962, 22307,    25,   198,  8421,   356,  5120,   597,  2252,    11,\n",
       "           3285,   502,  2740,    13,   198,   198,  3237,    25,   198,  5248,\n",
       "            461,    11,  2740,    13,   198,   198,  5962, 22307,    25,   198,\n",
       "           1639,   389]], device='cuda:0'),\n",
       " tensor([[22307,    25,   198,  8421,   356,  5120,   597,  2252,    11,  3285,\n",
       "            502,  2740,    13,   198,   198,  3237,    25,   198,  5248,   461,\n",
       "             11,  2740,    13,   198,   198,  5962, 22307,    25,   198,  1639,\n",
       "            389,   477]], device='cuda:0'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = trainloader.next_batch()\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GPT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGPT\u001b[49m(GPTConfig)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GPT' is not defined"
     ]
    }
   ],
   "source": [
    "model = GPT(GPTConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 32]), torch.Size([128]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(tokens[:128]).view(4, 32)\n",
    "x.shape, x.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokens = torch.tensor(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split, batch_size=32, block_size = 128):\n",
    "    indxs = torch.randint(0, len(split) - block_size, (batch_size, ))\n",
    "    x = torch.stack([split[i: i + block_size] for i in indxs])\n",
    "    y = torch.stack([split[i+1: i + block_size + 1] for i in indxs])\n",
    "    x, y = x.to('cuda'), y.to('cuda')\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  287,  1745,    11,   198,  6653, 18887,  4957,    11,  4950, 20828,\n",
       "         22260,    11,   198,  1870,   607, 34224,    82,   422,   502,   290,\n",
       "           584,   517,    11,   198,    50,  5013,   669,   284,   607,   290,\n",
       "         14987,   287,   616,  1842,    11,   198, 15979,  2752,   340,   257,\n",
       "          1517,  5340,    11,   198,  1890,   883, 22448,   314,   423,   878,\n",
       "         28779,   276,    11,   198,  2504,  1683, 18341,   283,  1437,   481,\n",
       "           307, 36440,  1549,    26,   198, 26583,   428,  1502, 22027, 18226,\n",
       "         12523, 20486,     6,   268,    11,   198,  2504,  4844,  2236,   423,\n",
       "          1895, 12722, 41227,  6888,   198,    51,   359, 18341,   283,  1437,\n",
       "           262,  1090,   301,   423,  1392,   257,  5229,    13,   198,   198,\n",
       "         10761,  5883,  9399,    25,   198,    42,   776,   283,  1437,   262,\n",
       "          1090,   301,     0,   198,    32,  3670,   329,   257, 25920,   286,\n",
       "           477,  8714,   262,  5290,    13,   198,   198,    39],\n",
       "        device='cuda:0'),\n",
       " tensor([ 1745,    11,   198,  6653, 18887,  4957,    11,  4950, 20828, 22260,\n",
       "            11,   198,  1870,   607, 34224,    82,   422,   502,   290,   584,\n",
       "           517,    11,   198,    50,  5013,   669,   284,   607,   290, 14987,\n",
       "           287,   616,  1842,    11,   198, 15979,  2752,   340,   257,  1517,\n",
       "          5340,    11,   198,  1890,   883, 22448,   314,   423,   878, 28779,\n",
       "           276,    11,   198,  2504,  1683, 18341,   283,  1437,   481,   307,\n",
       "         36440,  1549,    26,   198, 26583,   428,  1502, 22027, 18226, 12523,\n",
       "         20486,     6,   268,    11,   198,  2504,  4844,  2236,   423,  1895,\n",
       "         12722, 41227,  6888,   198,    51,   359, 18341,   283,  1437,   262,\n",
       "          1090,   301,   423,  1392,   257,  5229,    13,   198,   198, 10761,\n",
       "          5883,  9399,    25,   198,    42,   776,   283,  1437,   262,  1090,\n",
       "           301,     0,   198,    32,  3670,   329,   257, 25920,   286,   477,\n",
       "          8714,   262,  5290,    13,   198,   198,    39,  9863],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_batch(tokens)\n",
    "x[0], y[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
